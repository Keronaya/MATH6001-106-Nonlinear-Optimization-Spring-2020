
#MATH6001-106. Nonlinear Optimization in Machine Learning.#

Programming Project 2.

Consider a neural network with one hidden layer that consists of $p$ neurons and input $x\in \mathbb{R}^1$, output $y\in \mathbb{R}^1$. The neural network function has the form 
$y(x)=\sum\limits_{j=1}^p c_j \sigma(a_j x- b_j) \ , $
where $\mathbf{a}=a_j, \mathbf{b}=b_j$ and $\mathbf{c}=c_j$ are the neural network weights. Assume $(a_j, b_j, c_j)\sim \mathcal{N}(0, I_3)$, $j=1,2,â€¦,p$ is a family of i.i.d multivariate normal distributions. For different realizations of $(a_j, b_j, c_j)$, plot the function $y(x)$ on $x-y$ graph. Experiment different hidden layer sizes.

Results are attached.
